#!/bin/bash

# Log Performance Monitoring Script
# Monitors and analyzes log processing performance

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m'

# Configuration
LOKI_URL="http://loki:3100"
PROMETHEUS_URL="http://prometheus:9090"
LOG_DIR="{{ logs_dir }}"
DOCKER_DIR="{{ docker_dir }}"
PERFORMANCE_LOG="{{ docker_dir }}/monitoring/logging/performance.log"

# Function to show help
show_help() {
    echo -e "${CYAN}Log Performance Monitoring Script${NC}"
    echo "Usage: $0 [command] [options]"
    echo ""
    echo "Commands:"
    echo "  monitor [duration]  - Monitor log performance for specified duration (default: 1h)"
    echo "  analyze [period]    - Analyze performance for specified period (default: 24h)"
    echo "  bottlenecks         - Identify performance bottlenecks"
    echo "  recommendations     - Generate performance recommendations"
    echo "  report [period]     - Generate performance report"
    echo "  help                - Show this help"
    echo ""
    echo "Examples:"
    echo "  $0 monitor 30m"
    echo "  $0 analyze 7d"
    echo "  $0 bottlenecks"
    echo "  $0 report 24h"
}

# Function to query Prometheus metrics
query_prometheus() {
    local query="$1"
    
    curl -s -G "$PROMETHEUS_URL/api/v1/query" \
        --data-urlencode "query=$query" | jq -r '.data.result[0].value[1] // "0"' 2>/dev/null
}

# Function to monitor log performance
monitor_performance() {
    local duration="${1:-1h}"
    local interval=30
    local iterations=$(( $(echo "$duration" | sed 's/[^0-9]//g') * 60 / interval ))
    
    echo -e "${BLUE}Monitoring log performance for $duration${NC}"
    echo "Interval: ${interval}s, Iterations: $iterations"
    echo "----------------------------------------"
    
    # Create performance log file
    mkdir -p "$(dirname "$PERFORMANCE_LOG")"
    echo "# Log Performance Monitoring - Started at $(date)" > "$PERFORMANCE_LOG"
    echo "# Duration: $duration, Interval: ${interval}s" >> "$PERFORMANCE_LOG"
    echo "# Timestamp,LogIngestionRate,LogProcessingTime,ErrorRate,WarningRate,ActiveServices" >> "$PERFORMANCE_LOG"
    
    for ((i=1; i<=iterations; i++)); do
        local timestamp=$(date +%s)
        local ingestion_rate=$(query_prometheus "rate(loki_log_entries_total[5m])")
        local processing_time=$(query_prometheus "histogram_quantile(0.95, rate(loki_request_duration_seconds_bucket[5m]))")
        local error_rate=$(query_prometheus "rate(loki_log_entries_total{level=\"error\"}[5m])")
        local warning_rate=$(query_prometheus "rate(loki_log_entries_total{level=\"warn\"}[5m])")
        local active_services=$(query_prometheus "count(up{job=~\"promtail|loki\"})")
        
        echo "$timestamp,$ingestion_rate,$processing_time,$error_rate,$warning_rate,$active_services" >> "$PERFORMANCE_LOG"
        
        # Display current status
        echo -e "${GREEN}[$(date '+%H:%M:%S')]${NC} Ingestion: ${CYAN}${ingestion_rate}${NC} logs/s, Processing: ${YELLOW}${processing_time}s${NC}, Errors: ${RED}${error_rate}${NC}/s"
        
        sleep $interval
    done
    
    echo -e "${GREEN}Monitoring completed. Results saved to: $PERFORMANCE_LOG${NC}"
}

# Function to analyze performance
analyze_performance() {
    local period="${1:-24h}"
    
    echo -e "${BLUE}Analyzing log performance for $period${NC}"
    echo "----------------------------------------"
    
    # Get performance metrics
    local avg_ingestion=$(query_prometheus "avg_over_time(rate(loki_log_entries_total[5m])[$period])")
    local max_ingestion=$(query_prometheus "max_over_time(rate(loki_log_entries_total[5m])[$period])")
    local avg_processing=$(query_prometheus "avg_over_time(histogram_quantile(0.95, rate(loki_request_duration_seconds_bucket[5m]))[$period])")
    local max_processing=$(query_prometheus "max_over_time(histogram_quantile(0.95, rate(loki_request_duration_seconds_bucket[5m]))[$period])")
    local total_errors=$(query_prometheus "sum_over_time(rate(loki_log_entries_total{level=\"error\"}[5m])[$period])")
    local total_warnings=$(query_prometheus "sum_over_time(rate(loki_log_entries_total{level=\"warn\"}[5m])[$period])")
    
    echo -e "${CYAN}Performance Summary for $period:${NC}"
    echo -e "  Average Ingestion Rate: ${GREEN}${avg_ingestion}${NC} logs/s"
    echo -e "  Peak Ingestion Rate: ${YELLOW}${max_ingestion}${NC} logs/s"
    echo -e "  Average Processing Time: ${GREEN}${avg_processing}${NC}s"
    echo -e "  Peak Processing Time: ${YELLOW}${max_processing}${NC}s"
    echo -e "  Total Errors: ${RED}${total_errors}${NC}"
    echo -e "  Total Warnings: ${YELLOW}${total_warnings}${NC}"
    
    # Performance assessment
    echo ""
    echo -e "${CYAN}Performance Assessment:${NC}"
    
    if (( $(echo "$avg_ingestion > 1000" | bc -l) )); then
        echo -e "  ${YELLOW}⚠ High average ingestion rate detected${NC}"
    else
        echo -e "  ${GREEN}✓ Ingestion rate is within normal range${NC}"
    fi
    
    if (( $(echo "$avg_processing > 1" | bc -l) )); then
        echo -e "  ${YELLOW}⚠ High average processing time detected${NC}"
    else
        echo -e "  ${GREEN}✓ Processing time is within normal range${NC}"
    fi
    
    if (( $(echo "$total_errors > 100" | bc -l) )); then
        echo -e "  ${RED}✗ High error rate detected${NC}"
    else
        echo -e "  ${GREEN}✓ Error rate is acceptable${NC}"
    fi
}

# Function to identify bottlenecks
identify_bottlenecks() {
    echo -e "${BLUE}Identifying Performance Bottlenecks${NC}"
    echo "----------------------------------------"
    
    # Check Loki performance
    local loki_cpu=$(query_prometheus "rate(process_cpu_seconds_total{job=\"loki\"}[5m]) * 100")
    local loki_memory=$(query_prometheus "process_resident_memory_bytes{job=\"loki\"} / 1024 / 1024")
    local loki_goroutines=$(query_prometheus "go_goroutines{job=\"loki\"}")
    
    echo -e "${CYAN}Loki Performance:${NC}"
    echo -e "  CPU Usage: ${YELLOW}${loki_cpu}%${NC}"
    echo -e "  Memory Usage: ${YELLOW}${loki_memory} MB${NC}"
    echo -e "  Goroutines: ${YELLOW}${loki_goroutines}${NC}"
    
    # Check Promtail performance
    local promtail_cpu=$(query_prometheus "rate(process_cpu_seconds_total{job=\"promtail\"}[5m]) * 100")
    local promtail_memory=$(query_prometheus "process_resident_memory_bytes{job=\"promtail\"} / 1024 / 1024")
    local promtail_goroutines=$(query_prometheus "go_goroutines{job=\"promtail\"}")
    
    echo -e "${CYAN}Promtail Performance:${NC}"
    echo -e "  CPU Usage: ${YELLOW}${promtail_cpu}%${NC}"
    echo -e "  Memory Usage: ${YELLOW}${promtail_memory} MB${NC}"
    echo -e "  Goroutines: ${YELLOW}${promtail_goroutines}${NC}"
    
    # Check disk I/O
    local disk_io=$(query_prometheus "rate(node_disk_io_time_seconds_total[5m]) * 100")
    echo -e "${CYAN}Disk I/O:${NC}"
    echo -e "  I/O Utilization: ${YELLOW}${disk_io}%${NC}"
    
    # Identify bottlenecks
    echo ""
    echo -e "${CYAN}Bottleneck Analysis:${NC}"
    
    if (( $(echo "$loki_cpu > 80" | bc -l) )); then
        echo -e "  ${RED}✗ Loki CPU usage is high - consider scaling${NC}"
    fi
    
    if (( $(echo "$loki_memory > 2048" | bc -l) )); then
        echo -e "  ${RED}✗ Loki memory usage is high - consider increasing limits${NC}"
    fi
    
    if (( $(echo "$promtail_cpu > 50" | bc -l) )); then
        echo -e "  ${YELLOW}⚠ Promtail CPU usage is elevated${NC}"
    fi
    
    if (( $(echo "$disk_io > 80" | bc -l) )); then
        echo -e "  ${RED}✗ Disk I/O is saturated - consider SSD or optimization${NC}"
    fi
}

# Function to generate recommendations
generate_recommendations() {
    echo -e "${BLUE}Performance Recommendations${NC}"
    echo "----------------------------------------"
    
    local avg_ingestion=$(query_prometheus "avg_over_time(rate(loki_log_entries_total[5m])[1h])")
    local avg_processing=$(query_prometheus "avg_over_time(histogram_quantile(0.95, rate(loki_request_duration_seconds_bucket[5m]))[1h])")
    local loki_cpu=$(query_prometheus "rate(process_cpu_seconds_total{job=\"loki\"}[5m]) * 100")
    local loki_memory=$(query_prometheus "process_resident_memory_bytes{job=\"loki\"} / 1024 / 1024")
    
    echo -e "${CYAN}Immediate Actions:${NC}"
    
    if (( $(echo "$avg_ingestion > 2000" | bc -l) )); then
        echo -e "  ${RED}• Scale Loki horizontally - add more replicas${NC}"
        echo -e "  ${RED}• Implement log sampling for high-volume services${NC}"
    fi
    
    if (( $(echo "$avg_processing > 2" | bc -l) )); then
        echo -e "  ${YELLOW}• Optimize log queries and indexes${NC}"
        echo -e "  ${YELLOW}• Review log retention policies${NC}"
    fi
    
    if (( $(echo "$loki_cpu > 80" | bc -l) )); then
        echo -e "  ${RED}• Increase Loki CPU limits${NC}"
        echo -e "  ${RED}• Consider dedicated Loki instances${NC}"
    fi
    
    if (( $(echo "$loki_memory > 2048" | bc -l) )); then
        echo -e "  ${RED}• Increase Loki memory limits${NC}"
        echo -e "  ${RED}• Review chunk storage configuration${NC}"
    fi
    
    echo ""
    echo -e "${CYAN}Long-term Optimizations:${NC}"
    echo -e "  ${BLUE}• Implement log aggregation at service level${NC}"
    echo -e "  ${BLUE}• Use structured logging to reduce parsing overhead${NC}"
    echo -e "  ${BLUE}• Implement log compression for storage efficiency${NC}"
    echo -e "  ${BLUE}• Consider distributed logging architecture${NC}"
    echo -e "  ${BLUE}• Implement log streaming for real-time processing${NC}"
}

# Function to generate performance report
generate_report() {
    local period="${1:-24h}"
    local report_file="{{ docker_dir }}/monitoring/logging/performance-report-$(date +%Y%m%d-%H%M%S).txt"
    
    echo -e "${BLUE}Generating Performance Report${NC}"
    echo "Report will be saved to: $report_file"
    
    {
        echo "Log Performance Report"
        echo "Generated: $(date)"
        echo "Period: $period"
        echo "========================================"
        echo ""
        
        # Performance metrics
        echo "PERFORMANCE METRICS"
        echo "-------------------"
        local avg_ingestion=$(query_prometheus "avg_over_time(rate(loki_log_entries_total[5m])[$period])")
        local max_ingestion=$(query_prometheus "max_over_time(rate(loki_log_entries_total[5m])[$period])")
        local avg_processing=$(query_prometheus "avg_over_time(histogram_quantile(0.95, rate(loki_request_duration_seconds_bucket[5m]))[$period])")
        local total_errors=$(query_prometheus "sum_over_time(rate(loki_log_entries_total{level=\"error\"}[5m])[$period])")
        
        echo "Average Ingestion Rate: ${avg_ingestion} logs/s"
        echo "Peak Ingestion Rate: ${max_ingestion} logs/s"
        echo "Average Processing Time: ${avg_processing}s"
        echo "Total Errors: ${total_errors}"
        echo ""
        
        # Resource usage
        echo "RESOURCE USAGE"
        echo "--------------"
        local loki_cpu=$(query_prometheus "rate(process_cpu_seconds_total{job=\"loki\"}[5m]) * 100")
        local loki_memory=$(query_prometheus "process_resident_memory_bytes{job=\"loki\"} / 1024 / 1024")
        echo "Loki CPU Usage: ${loki_cpu}%"
        echo "Loki Memory Usage: ${loki_memory} MB"
        echo ""
        
        # Recommendations
        echo "RECOMMENDATIONS"
        echo "---------------"
        if (( $(echo "$avg_ingestion > 2000" | bc -l) )); then
            echo "- Scale Loki horizontally"
            echo "- Implement log sampling"
        fi
        if (( $(echo "$loki_cpu > 80" | bc -l) )); then
            echo "- Increase Loki CPU limits"
        fi
        if (( $(echo "$loki_memory > 2048" | bc -l) )); then
            echo "- Increase Loki memory limits"
        fi
        
    } > "$report_file"
    
    echo -e "${GREEN}Report generated: $report_file${NC}"
}

# Main script logic
case "${1:-help}" in
    "monitor")
        monitor_performance "$2"
        ;;
    "analyze")
        analyze_performance "$2"
        ;;
    "bottlenecks")
        identify_bottlenecks
        ;;
    "recommendations")
        generate_recommendations
        ;;
    "report")
        generate_report "$2"
        ;;
    "help"|*)
        show_help
        ;;
esac 